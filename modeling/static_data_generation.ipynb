{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product(*choices : np.array) -> pd.DataFrame:\n",
    "    num_axis = len(choices)\n",
    "    return pd.DataFrame(np.copy(np.vstack(np.vstack(np.meshgrid(*choices))).reshape(num_axis, -1).T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cartesian_success_results(attribute: int, discipline: int, num_dice: int = 2, applicable_focus: bool = False) -> pd.DataFrame:\n",
    "    d20 = np.arange(1, 21)\n",
    "    tn = attribute + discipline\n",
    "    cartesian_df = cartesian_product(*[d20] * num_dice)\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df[\"base_successes\"] = (cartesian_df <= tn).sum(axis=\"columns\")\n",
    "    results_df[\"critical_successes\"] = (cartesian_df == 1).sum(axis=\"columns\")\n",
    "    results_df[\"focus_successes\"] = (cartesian_df <= discipline ).sum(axis=\"columns\")\n",
    "    if applicable_focus:\n",
    "        results_df[\"successes\"] = results_df.loc[:, [\"base_successes\", \"focus_successes\"]].sum(axis=\"columns\")\n",
    "    else:\n",
    "        results_df[\"successes\"] = results_df.loc[:, [\"base_successes\", \"critical_successes\"]].sum(axis=\"columns\")\n",
    "    return results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_success_probability_table(enumerated_results: pd.DataFrame, normalize: bool = True) -> pd.DataFrame:\n",
    "    prob_table_s = enumerated_results[\"successes\"].value_counts(normalize=normalize, sort=False).sort_index(ascending=False).rename(\"exact successes\")\n",
    "    cum_prob_s = prob_table_s.cumsum().rename(\"cumulative successes\")\n",
    "    tab_df = pd.concat([prob_table_s, cum_prob_s], axis=1,).fillna(0).astype(prob_table_s.dtype)\n",
    "    return tab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success_prob_table(attribute: int, discipline: int, num_dice: int = 2, applicable_focus: bool = False, normalize: bool = True) -> pd.DataFrame:\n",
    "    cr_df = _cartesian_success_results(attribute=attribute, discipline=discipline, num_dice=num_dice, applicable_focus=applicable_focus)\n",
    "    p_table = _create_success_probability_table(cr_df, normalize=normalize)\n",
    "    return p_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_success_frequency_map(\n",
    "    attribute_min: int = 7,\n",
    "    attribute_max: int = 12,\n",
    "    discipline_min: int = 0,\n",
    "    discipline_max: int = 5,\n",
    "    dice_min: int = 1,\n",
    "    dice_max: int = 5\n",
    "    ):\n",
    "    from itertools import product, chain\n",
    "\n",
    "    attribute_range = range(attribute_min, attribute_max+1)\n",
    "    discipline_range = range(discipline_min, discipline_max+1)\n",
    "    target_range = range(attribute_min + discipline_min, attribute_max + discipline_max + 1)\n",
    "    dice_range = range(dice_min, dice_max+1)\n",
    "\n",
    "    no_focus_index = product(dice_range, [False], target_range, [0])\n",
    "    focus_index = product(dice_range, [True], attribute_range, discipline_range)\n",
    "    index_entries = chain(no_focus_index, focus_index)\n",
    "\n",
    "    frequency_table_map = dict()\n",
    "    for index_entry in index_entries:\n",
    "        num_die, focus, attribute, discipline = index_entry\n",
    "        freq_table = success_prob_table(attribute, discipline, num_die, focus, False)\n",
    "        freq_table = freq_table[\"exact successes\"].sort_index().to_list()\n",
    "        if focus:\n",
    "            frequency_table_map.setdefault(num_die, dict()).setdefault(focus, dict()).setdefault(attribute, dict())[discipline] = freq_table\n",
    "        else:\n",
    "            frequency_table_map.setdefault(num_die, dict()).setdefault(focus, dict())[attribute] = freq_table\n",
    "    return frequency_table_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cartesian_complications_results(num_dice: int = 2, complications_range_min: int = 1, complications_range_max: int = 5):\n",
    "    d20 = np.arange(1, 21)\n",
    "    cartesian_df = cartesian_product(*[d20] * num_dice)\n",
    "    complications = range(complications_range_min, complications_range_max+1)\n",
    "    res = pd.DataFrame()\n",
    "    for complications_range in complications:\n",
    "        res[f\"{complications_range}\"] = (cartesian_df > (20-complications_range)).sum(axis=\"columns\")\n",
    "    res.columns.name=\"complications_range\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_complications_probability_table(enumerated_results: pd.DataFrame, normalize: bool = True) -> pd.DataFrame:\n",
    "   value_series = [enumerated_results[col_name].value_counts(sort=False, normalize=normalize).sort_index() for col_name in enumerated_results]\n",
    "   res = pd.concat(value_series, axis=\"columns\").fillna(0).astype(value_series[0].dtype)\n",
    "   return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complications_probability_table(num_dice: int = 2, complications_range_min: int = 1, complications_range_max: int = 5, normalize=True):\n",
    "    ccr_df = _cartesian_complications_results(num_dice=num_dice, complications_range_min=complications_range_min, complications_range_max=complications_range_max)\n",
    "    p_table = _create_complications_probability_table(ccr_df, normalize=normalize)\n",
    "    return p_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_complications_frequency_map(\n",
    "    complications_range_min: int = 1,\n",
    "    complications_range_max: int = 5,\n",
    "    dice_min: int = 1,\n",
    "    dice_max: int = 5,\n",
    "):\n",
    "    res = dict()\n",
    "    for dice in range(dice_min, dice_max+1):\n",
    "        for column_name in (f_table:=complications_probability_table(num_dice=dice, complications_range_min=complications_range_min, complications_range_max=complications_range_max, normalize=False)):\n",
    "            res.setdefault(dice, dict())[column_name] = f_table[column_name].sort_index().to_list()\n",
    "    return res\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_files():\n",
    "    import json\n",
    "\n",
    "    json.dump(generate_success_frequency_map(), open(\"../sta-dice-roller/static-data/successes.json\", \"w\"))\n",
    "    json.dump(generate_complications_frequency_map(), open(\"../sta-dice-roller/static-data/complications.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_with_assists(lead_dice: list[list[int]], assist_dice: list[list[int]]) -> pd.DataFrame:\n",
    "    lead_array = np.array(lead_dice).T\n",
    "    assist_array = np.array(assist_dice).T\n",
    "    d20= np.arange(1,21)\n",
    "    cp_df = cartesian_product(*[d20]*(len(lead_dice) + len(assist_dice)))\n",
    "    successes_df = pd.DataFrame(cp_df.iloc[:, :len(lead_array)])\n",
    "    successes_df[\"lead_successes\"] = (cp_df.iloc[:, :len(lead_array[1])] <= lead_array[1]).sum(axis=\"columns\")\n",
    "    successes_df[\"lead_bonuses\"] = (cp_df.iloc[:, :len(lead_array[0])] <= lead_array[0]).sum(axis=\"columns\")\n",
    "    successes_df[\"lead_total\"] = (successes_df[\"lead_successes\"] + successes_df[\"lead_bonuses\"])\n",
    "    successes_df[\"assist_successes\"] = (cp_df.iloc[:, len(lead_array[1]):(len(lead_array[1])+len(assist_array[1]))] <= assist_array[1]).sum(axis=\"columns\")\n",
    "    successes_df[\"assist_bonuses\"] = (cp_df.iloc[:, len(lead_array[0]):(len(lead_array[0])+len(assist_array[1]))] <= assist_array[0]).sum(axis=\"columns\")\n",
    "    successes_df[\"assist_total\"] = successes_df[\"assist_successes\"] + successes_df[\"assist_bonuses\"]\n",
    "    successes_df[\"assist_total\"][successes_df[\"lead_total\"] == 0] = 0\n",
    "    successes_df[\"grand_total\"] = successes_df[\"lead_total\"] + successes_df[\"assist_total\"]\n",
    "    return successes_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3600\n",
       "1    28800\n",
       "2    69600\n",
       "3    48000\n",
       "4    10000\n",
       "Name: grand_total, dtype: int64"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dice = [[1, 8], [1, 8]]\n",
    "cartesian_results = pool_with_assists([[5,17],[5,17]], [[0,0], [0,0]])\n",
    "cartesian_results[\"grand_total\"].value_counts(sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
